
This version is from https://chatgpt.com/c/699b918d-a07c-8393-9207-d077e56c0206  
Exported as .doc and converted to .md using google docs will maintain references but now all code sections are formatted incorrectly. Try exporting later or reformat using claude %$*&)##!  
  
# Modern Docker tutorial with BuildKit, multi-stage builds, Compose, GitHub Actions, GHCR, and Azure

## Context and goals

The Microsoft Learn tutorial you shared is intentionally “linear”: pull an image, run it, then Dockerfile a single service, then push to a private Azure registry and run it on Azure. That teaches the mechanics, but most real projects quickly hit four realities:

You rarely ship **one container**; you ship a **stack** (web UI \+ API \+ database, at minimum). [\[1\]](https://docs.docker.com/compose/?utm_source=chatgpt.com)  
You want builds that are **fast, cacheable, reproducible, and CI-friendly**, which is why BuildKit and Buildx matter. [\[2\]](https://docs.docker.com/build/buildkit/?utm_source=chatgpt.com)  
You want production images that are **small and safer**, which is why multi-stage Dockerfiles are now a default technique. [\[3\]](https://docs.docker.com/build/building/multi-stage/?utm_source=chatgpt.com)  
You usually build and publish images via **CI/CD** (commonly GitHub Actions), and you publish them somewhere (commonly GHCR if you’re already in GitHub). [\[4\]](https://docs.github.com/actions/guides/publishing-docker-images?utm_source=chatgpt.com)

This tutorial modernizes the flow by building a small but realistic app, end-to-end:

* Start from a GitHub repo and develop in **GitHub Codespaces** using a **dev container**. [\[5\]](https://docs.github.com/codespaces/setting-up-your-project-for-codespaces/introduction-to-dev-containers)

* Use **Docker Compose** to develop and run a two-container stack locally. [\[6\]](https://docs.docker.com/compose/intro/compose-application-model/)

* Build both images with **BuildKit** (directly via Buildx) and **multi-stage Dockerfiles**. [\[7\]](https://docs.docker.com/build/buildkit/?utm_source=chatgpt.com)

* Use **GitHub Actions** CI to test, then build and push images to **GHCR**. [\[8\]](https://docs.github.com/actions/using-workflows/workflow-syntax-for-github-actions?utm_source=chatgpt.com)

* Deploy a production version to **Azure Container Apps**, with guidance on what changes for production (networking, secrets, persistence, scaling). [\[9\]](https://learn.microsoft.com/en-us/azure/container-apps/environment?utm_source=chatgpt.com)

What you’ll build:

Browser  
  |  
  v  
web container (Nginx, serves UI, proxies /api/\*)  
  |  
  v  
api container (FastAPI)  
  |  
  v  
SQLite database file (mounted volume)

This design keeps exactly **two containers**: a web interface container and a backend container whose persistence layer is SQLite.

## The modern concepts explained

**BuildKit and Buildx (what they are and why they matter)**  
BuildKit is the engine that executes Docker builds. Docker documents BuildKit as the “improved backend” and notes it is the default builder on Docker Desktop and Docker Engine as of version 23.0. [\[10\]](https://docs.docker.com/build/buildkit/?utm_source=chatgpt.com)  
Buildx is the CLI “front-end” that drives BuildKit; Docker’s build overview explains BuildKit resolves build instructions while Buildx monitors build status and prints progress. [\[11\]](https://docs.docker.com/build/concepts/overview/?utm_source=chatgpt.com)  
Practically, docker buildx build is the “modern” command that directly targets BuildKit and unlocks capabilities like multi-platform builds, explicit cache import/export, and flexible outputs. [\[12\]](https://docs.docker.com/reference/cli/docker/buildx/build/?utm_source=chatgpt.com)

Why “BuildKit vs docker build” is a real distinction: Docker CLI has evolved so docker build often uses BuildKit under the hood, but buildx is still the canonical way to use advanced BuildKit features consistently (especially in CI, and especially for caching and multi-platform). [\[13\]](https://docs.docker.com/build/buildkit/?utm_source=chatgpt.com)

**Multi-stage Dockerfiles (why they are the new default)**  
A multi-stage Dockerfile uses multiple FROM stages: you build in one stage, then copy only the runtime artifacts into a smaller runtime stage. Docker’s multi-stage docs emphasize that this helps optimize Dockerfiles and is particularly valuable for separating build-time dependencies from runtime. [\[14\]](https://docs.docker.com/build/building/multi-stage/?utm_source=chatgpt.com)  
Docker’s build best practices explicitly recommend multi-stage builds to reduce final image size and keep only what’s necessary to run. [\[15\]](https://docs.docker.com/build/building/best-practices/)

**Docker Compose (why it’s the right tool for local stacks)**  
Compose lets you define a multi-container application in a YAML “Compose file,” then create/start all services using the Compose CLI. [\[6\]](https://docs.docker.com/compose/intro/compose-application-model/)  
It also supports practical development ergonomics like controlling startup order via depends\_on and health checks, and using “profiles” to selectively enable optional services. [\[16\]](https://docs.docker.com/compose/how-tos/startup-order/?utm_source=chatgpt.com)  
Modern Docker also supports docker compose (no hyphen), and the CLI will auto-discover compose.yaml / docker-compose.yaml when you don’t pass \-f. [\[17\]](https://docs.docker.com/reference/cli/docker/compose/)

**CI/CD with GitHub Actions (what it automates)**  
A GitHub Actions workflow is a YAML-defined automated process made up of jobs. [\[18\]](https://docs.github.com/actions/using-workflows/workflow-syntax-for-github-actions?utm_source=chatgpt.com)  
For container projects, the common pattern is: run tests → build images → push images to a registry → deploy. GitHub’s own guide specifically covers building and publishing Docker images, including to GitHub Packages / GHCR. [\[19\]](https://docs.github.com/actions/guides/publishing-docker-images?utm_source=chatgpt.com)  
Docker’s official build-push-action is built around Buildx/BuildKit and supports features like multi-platform builds and caching. [\[20\]](https://github.com/docker/build-push-action?utm_source=chatgpt.com)

**GHCR (GitHub Container Registry) (what it is and the “gotchas”)**  
GitHub’s Container registry (GHCR) stores container images under your personal account or organization and lets you associate images with repositories; GitHub also documents granular permissions and access control options. [\[21\]](https://docs.github.com/packages/working-with-a-github-packages-registry/working-with-the-container-registry?utm_source=chatgpt.com)  
GitHub Packages docs highlight that Actions workflows can use GITHUB\_TOKEN to work with packages without needing a long-lived PAT, but you must configure workflow permissions appropriately (notably packages: write when pushing). [\[22\]](https://docs.github.com/en/packages/learn-github-packages/about-permissions-for-github-packages?utm_source=chatgpt.com)

**Codespaces \+ dev containers (why they fit this workflow)**  
Codespaces creates your dev environment from a “dev container” config; GitHub documents devcontainer.json as the primary configuration file, usually located under .devcontainer/. [\[5\]](https://docs.github.com/codespaces/setting-up-your-project-for-codespaces/introduction-to-dev-containers)  
Importantly: when you rebuild a codespace container, changes outside /workspaces are cleared—this bites people who install tooling ad-hoc instead of codifying it in the dev container. [\[5\]](https://docs.github.com/codespaces/setting-up-your-project-for-codespaces/introduction-to-dev-containers)

## Repository bootstrap and Codespaces-first development

This section is written as a “README you can follow.” It assumes you start from an empty repo.

### Create the GitHub repo

From your local machine (or from the GitHub UI), create a repository. If you use GitHub CLI:

gh repo create modern-docker-stack \--public \--clone  
cd modern-docker-stack

Commit early and often; the CI sections later assume the default branch is main.

### Create the project structure

Create these directories:

mkdir \-p api/app web/nginx .github/workflows .devcontainer

A simple target tree (you’ll create the contents in later steps):

.  
├── .devcontainer/  
│   └── devcontainer.json  
├── .github/workflows/  
│   ├── ci.yml  
│   └── deploy-azure.yml  
├── api/  
│   ├── Dockerfile  
│   ├── requirements.txt  
│   └── app/  
│       └── main.py  
├── web/  
│   ├── Dockerfile  
│   ├── docker-entrypoint.sh  
│   ├── nginx/  
│   │   └── default.conf.template  
│   └── static/  
│       ├── index.html  
│       └── app.js  
├── compose.yaml  
├── compose.dev.yaml  
├── .dockerignore  
└── README.md

### Add the Codespaces dev container config

Create .devcontainer/devcontainer.json:

{  
  "name": "modern-docker-stack",  
  // Use a dev container image with common tooling; keep project-specific tools in "features".  
  "image": "mcr.microsoft.com/devcontainers/python:1-3.12",  
  "features": {  
    // Enables running Docker/Compose from inside the codespace (child containers).  
    "ghcr.io/devcontainers/features/docker-in-docker:2": {},  
    // Frontend tooling (optional if you later switch away from static JS).  
    "ghcr.io/devcontainers/features/node:1": { "version": "20" },  
    // Helpful for repo automation from the terminal.  
    "ghcr.io/devcontainers/features/github-cli:1": {}  
  },  
  "forwardPorts": \[8080\],  
  "postCreateCommand": "python \-m pip install \--upgrade pip && pip install \-r api/requirements.txt",  
  "customizations": {  
    "vscode": {  
      "extensions": \[  
        "ms-azuretools.vscode-docker",  
        "ms-python.python"  
      \]  
    }  
  }  
}

What’s happening here: Codespaces will build a development container from this configuration, ensuring every developer (and prebuild) gets the same baseline toolchain. GitHub’s docs describe devcontainer.json as the primary Codespaces environment definition and recommend keeping it “standard” for the team, not personal preferences. [\[5\]](https://docs.github.com/codespaces/setting-up-your-project-for-codespaces/introduction-to-dev-containers)

Pitfall: if you “just install” tools interactively and later rebuild the container, those changes may disappear if they were made outside /workspaces. That’s why devcontainer config matters. [\[5\]](https://docs.github.com/codespaces/setting-up-your-project-for-codespaces/introduction-to-dev-containers)

Now commit this baseline:

git add .devcontainer/devcontainer.json  
git commit \-m "Add Codespaces dev container"  
git push

Open the repo in Codespaces (GitHub UI → Code → Codespaces). When it finishes, you should have Docker available in the codespace terminal (this is what the docker-in-docker feature is for).

## Local runtime with Docker Compose

### Compose file discovery and why we name it compose.yaml

Docker’s docker compose CLI will traverse the working directory and parents looking for compose.yaml or docker-compose.yaml if you don’t pass \-f. [\[17\]](https://docs.docker.com/reference/cli/docker/compose/)  
We’ll use compose.yaml as the explicit modern default, and we’ll also use an additional file compose.dev.yaml to layer dev-only behavior via docker compose \-f ... \-f .... This layering behavior is documented by Docker’s Compose CLI reference. [\[17\]](https://docs.docker.com/reference/cli/docker/compose/)

### Backend API implementation (FastAPI \+ SQLite)

Create api/requirements.txt:

fastapi\>=0.110,\<1.0  
uvicorn\>=0.29,\<1.0

Create api/app/main.py:

import os  
import sqlite3  
from datetime import datetime, timezone  
from typing import List

from fastapi import FastAPI, HTTPException  
from pydantic import BaseModel

DB\_PATH \= os.getenv("DB\_PATH", "/data/app.db")

app \= FastAPI()

def \_connect() \-\> sqlite3.Connection:  
    \# check\_same\_thread=False allows usage across threads (uvicorn workers/threads).  
    conn \= sqlite3.connect(DB\_PATH, check\_same\_thread=False)  
    conn.row\_factory \= sqlite3.Row  
    return conn

def \_init\_db() \-\> None:  
    os.makedirs(os.path.dirname(DB\_PATH), exist\_ok=True)  
    with \_connect() as conn:  
        \# WAL improves concurrency for many-read / occasional-write workloads.  
        conn.execute("PRAGMA journal\_mode=WAL;")  
        conn.execute(  
            """  
            CREATE TABLE IF NOT EXISTS items (  
              id INTEGER PRIMARY KEY AUTOINCREMENT,  
              text TEXT NOT NULL,  
              created\_at TEXT NOT NULL  
            )  
            """  
        )

@app.on\_event("startup")  
def on\_startup() \-\> None:  
    \_init\_db()

class ItemCreate(BaseModel):  
    text: str

class Item(BaseModel):  
    id: int  
    text: str  
    created\_at: str

@app.get("/api/healthz")  
def healthz() \-\> dict:  
    return {"status": "ok"}

@app.get("/api/items", response\_model=List\[Item\])  
def list\_items() \-\> List\[Item\]:  
    with \_connect() as conn:  
        rows \= conn.execute(  
            "SELECT id, text, created\_at FROM items ORDER BY id DESC"  
        ).fetchall()  
    return \[Item(\*\*dict(r)) for r in rows\]

@app.post("/api/items", response\_model=Item, status\_code=201)  
def create\_item(payload: ItemCreate) \-\> Item:  
    text \= payload.text.strip()  
    if not text:  
        raise HTTPException(status\_code=400, detail="text must not be empty")

    created\_at \= datetime.now(timezone.utc).isoformat()  
    with \_connect() as conn:  
        cur \= conn.execute(  
            "INSERT INTO items(text, created\_at) VALUES(?, ?)",  
            (text, created\_at),  
        )  
        new\_id \= cur.lastrowid

        row \= conn.execute(  
            "SELECT id, text, created\_at FROM items WHERE id \= ?",  
            (new\_id,),  
        ).fetchone()

    return Item(\*\*dict(row))

What’s happening: the API container owns the SQLite file at DB\_PATH (default /data/app.db). We’ll mount /data as a named volume in Compose so the DB persists across container restarts.

### Web container implementation (Nginx \+ static UI \+ reverse proxy)

Create web/static/index.html:

\<\!doctype html\>  
\<html lang="en"\>  
  \<head\>  
    \<meta charset="utf-8" /\>  
    \<meta name="viewport" content="width=device-width,initial-scale=1" /\>  
    \<title\>Modern Docker Stack\</title\>  
    \<style\>  
      body { font-family: system-ui, sans-serif; max-width: 720px; margin: 2rem auto; padding: 0 1rem; }  
      input, button { font-size: 1rem; padding: 0.5rem; }  
      li { margin: 0.4rem 0; }  
      small { color: \#666; }  
      .row { display: flex; gap: 0.5rem; }  
      .row input { flex: 1; }  
    \</style\>  
  \</head\>  
  \<body\>  
    \<h1\>Modern Docker Stack\</h1\>  
    \<p\>\<small\>UI served by \<code\>web\</code\> container. API proxied via \<code\>/api\</code\>.\</small\>\</p\>

    \<div class="row"\>  
      \<input id="text" placeholder="Type an item..." /\>  
      \<button id="add"\>Add\</button\>  
    \</div\>

    \<h2\>Items\</h2\>  
    \<ul id="items"\>\</ul\>

    \<script src="/app.js"\>\</script\>  
  \</body\>  
\</html\>

Create web/static/app.js:

async function fetchItems() {  
  const res \= await fetch("/api/items");  
  const items \= await res.json();

  const ul \= document.getElementById("items");  
  ul.innerHTML \= "";  
  for (const it of items) {  
    const li \= document.createElement("li");  
    li.textContent \= \`${it.text} \`;  
    const sm \= document.createElement("small");  
    sm.textContent \= \`(${it.created\_at})\`;  
    li.appendChild(sm);  
    ul.appendChild(li);  
  }  
}

async function addItem() {  
  const input \= document.getElementById("text");  
  const text \= input.value.trim();  
  if (\!text) return;

  const res \= await fetch("/api/items", {  
    method: "POST",  
    headers: {"Content-Type": "application/json"},  
    body: JSON.stringify({ text })  
  });

  if (\!res.ok) {  
    alert("API error: " \+ (await res.text()));  
    return;  
  }

  input.value \= "";  
  await fetchItems();  
}

document.getElementById("add").addEventListener("click", addItem);  
document.getElementById("text").addEventListener("keydown", (e) \=\> {  
  if (e.key \=== "Enter") addItem();  
});

fetchItems();

Create the Nginx config template web/nginx/default.conf.template:

server {  
  listen 80;

  location / {  
    root /usr/share/nginx/html;  
    try\_files $uri $uri/ /index.html;  
  }

  \# Reverse proxy so browsers never need direct access to the API container.  
  location /api/ {  
    proxy\_set\_header Host $host;  
    proxy\_set\_header X-Real-IP $remote\_addr;  
    proxy\_set\_header X-Forwarded-Proto $scheme;

    proxy\_pass ${API\_UPSTREAM};  
  }  
}

Create web/docker-entrypoint.sh:

\#\!/usr/bin/env sh  
set \-eu

: "${API\_UPSTREAM:=http://api:8000}"

\# Render the nginx config with the API\_UPSTREAM value.  
envsubst '$API\_UPSTREAM' \\  
  \< /etc/nginx/conf.d/default.conf.template \\  
  \> /etc/nginx/conf.d/default.conf

exec nginx \-g 'daemon off;'

### Compose files

Create compose.yaml:

services:  
  api:  
    build:  
      context: .  
      dockerfile: api/Dockerfile  
    environment:  
      DB\_PATH: /data/app.db  
    volumes:  
      \- db-data:/data  
    healthcheck:  
      test: \["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://127.0.0.1:8000/api/healthz')"\]  
      interval: 5s  
      timeout: 2s  
      retries: 20

  web:  
    build:  
      context: .  
      dockerfile: web/Dockerfile  
    ports:  
      \- "8080:80"  
    environment:  
      \# In Compose networking, "api" resolves as the api service container.  
      API\_UPSTREAM: "http://api:8000"  
    depends\_on:  
      api:  
        condition: service\_healthy

volumes:  
  db-data:

Why depends\_on \+ healthcheck: Compose starts services in dependency order, and Docker documents using depends\_on with health checks to manage startup order more reliably. [\[23\]](https://docs.docker.com/compose/how-tos/startup-order/?utm_source=chatgpt.com)

Now create a dev override compose.dev.yaml to expose the API port on localhost (helpful for debugging/curling the API directly):

services:  
  api:  
    ports:  
      \- "8000:8000"

This file layering model is exactly what Docker’s compose CLI reference describes for multiple \-f files. [\[17\]](https://docs.docker.com/reference/cli/docker/compose/)

### Run locally (in Codespaces or locally)

From repo root:

docker compose \-f compose.yaml \-f compose.dev.yaml up \--build

Expected output (example):

\[+\] Building 12.4s (20/20) FINISHED  
 \=\> \[api runtime\] exporting to image  
 \=\> \=\> naming to docker.io/library/modern-docker-stack-api  
 \=\> \[web runtime\] exporting to image  
 \=\> \=\> naming to docker.io/library/modern-docker-stack-web  
\[+\] Running 3/3  
 ✔ Network modern-docker-stack\_default  Created  
 ✔ Container modern-docker-stack-api-1  Started  
 ✔ Container modern-docker-stack-web-1  Started

Then:

* Open http://localhost:8080 (Codespaces will prompt to forward/preview port 8080).

* Add an item; refresh; confirm persistence even after restarting containers.

Debugging checks:

docker compose ps  
curl \-s http://localhost:8000/api/healthz  
curl \-s http://localhost:8000/api/items

Pitfalls you’ll likely hit:

If depends\_on is used without a healthcheck, Compose may start web before the API is actually ready; Docker explicitly calls out health checks as part of startup-order control. [\[23\]](https://docs.docker.com/compose/how-tos/startup-order/?utm_source=chatgpt.com)  
If you store your SQLite DB inside the container filesystem without a volume, you’ll lose data every time the container is recreated; Docker’s best practices emphasize containers should be ephemeral and state should live outside. [\[24\]](https://docs.docker.com/build/building/best-practices/)

Commit these baseline files:

git add api web compose.yaml compose.dev.yaml  
git commit \-m "Add two-container app (web \+ api) with Compose"  
git push

## Container images with BuildKit and multi-stage Dockerfiles

### .dockerignore (small build context \= faster builds)

Create .dockerignore at repo root:

.git  
.github  
\*\*/\_\_pycache\_\_  
\*\*/\*.pyc  
\*\*/\*.pyo  
\*\*/.pytest\_cache  
\*\*/node\_modules  
\*\*/dist  
\*\*/.DS\_Store

Docker’s build best practices specifically call out using .dockerignore to exclude files not relevant to the build so you don’t send unnecessary context to the builder. [\[25\]](https://docs.docker.com/build/building/best-practices/)

### API Dockerfile (multi-stage \+ BuildKit cache mounts)

Create api/Dockerfile:

\# syntax=docker/dockerfile:1.7

FROM python:3.12-slim AS builder  
WORKDIR /build

COPY api/requirements.txt .

\# BuildKit cache mount speeds up pip downloads across builds.  
RUN \--mount=type=cache,target=/root/.cache/pip \\  
    pip wheel \--wheel-dir=/wheels \-r requirements.txt

COPY api/app ./app

FROM python:3.12-slim AS runtime  
ENV PYTHONUNBUFFERED=1  
WORKDIR /app

\# Create a non-root user (best practice).  
RUN adduser \--disabled-password \--gecos "" appuser \\  
    && mkdir \-p /data \\  
    && chown \-R appuser:appuser /data

COPY \--from=builder /wheels /wheels  
RUN \--mount=type=cache,target=/root/.cache/pip \\  
    pip install \--no-cache-dir /wheels/\* \\  
    && rm \-rf /wheels

COPY \--from=builder /build/app ./app

USER appuser  
EXPOSE 8000

CMD \["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"\]

What’s happening, and why it’s “modern”:

The \# syntax=... directive tells BuildKit which Dockerfile frontend version to use; Docker documents this “custom Dockerfile syntax” mechanism as a BuildKit feature. [\[26\]](https://docs.docker.com/build/buildkit/frontend/?utm_source=chatgpt.com)  
RUN \--mount=type=cache is a BuildKit feature that provides persistent cache locations to reuse downloads and speed up rebuilds; Docker documents cache mounts and the RUN \--mount flag. [\[27\]](https://docs.docker.com/build/cache/optimize/?utm_source=chatgpt.com)  
Multi-stage separation (builder → runtime) follows Docker’s recommended pattern for smaller runtime images. [\[3\]](https://docs.docker.com/build/building/multi-stage/?utm_source=chatgpt.com)  
Running as non-root is a documented best practice when the service doesn’t need privileges. [\[28\]](https://docs.docker.com/build/building/best-practices/)

### Web Dockerfile (multi-stage \+ runtime template)

Create web/Dockerfile:

\# syntax=docker/dockerfile:1.7

FROM nginx:1.27-alpine AS runtime

COPY web/static/ /usr/share/nginx/html/  
COPY web/nginx/default.conf.template /etc/nginx/conf.d/default.conf.template  
COPY web/docker-entrypoint.sh /docker-entrypoint.sh

RUN chmod \+x /docker-entrypoint.sh

ENV API\_UPSTREAM="http://api:8000"  
EXPOSE 80  
ENTRYPOINT \["/docker-entrypoint.sh"\]

Even though this web container doesn’t have a “build step,” it’s still structured so configuration is injected at runtime via environment variables (this matters in Azure, where the upstream host won’t be api:8000).

### Using Buildx locally (explicit BuildKit)

You can build with Compose, but to practice the “modern” BuildKit-native flow, build explicitly with Buildx:

docker buildx create \--use  
docker buildx build \-f api/Dockerfile \-t local/api:dev \--load .  
docker buildx build \-f web/Dockerfile \-t local/web:dev \--load .

Docker documents docker buildx build as the command that starts a build using BuildKit. [\[29\]](https://docs.docker.com/reference/cli/docker/buildx/build/?utm_source=chatgpt.com)  
And Docker’s BuildKit docs explain that BuildKit is the backend replacing the legacy builder. [\[30\]](https://docs.docker.com/build/buildkit/?utm_source=chatgpt.com)

## CI/CD with GitHub Actions and GHCR

This section sets up a practical CI pipeline with these goals:

* On pull requests: build images \+ run basic API tests (no pushing).

* On pushes to main: build \+ test \+ push both images to GHCR with cache enabled.

* Tag images in a way you can trace to a commit (SHA tags), not just latest.

### GHCR naming convention and permissions

We’ll publish images under:

* ghcr.io/\<OWNER\>/\<REPO\>-api:\<tag\>

* ghcr.io/\<OWNER\>/\<REPO\>-web:\<tag\>

GitHub’s container registry documentation describes GHCR as the place to store container images under your account/org and associate them with a repository. [\[31\]](https://docs.github.com/packages/working-with-a-github-packages-registry/working-with-the-container-registry?utm_source=chatgpt.com)

Permissions gotcha: GitHub Packages supports using GITHUB\_TOKEN in workflows (instead of a PAT), but you must grant workflow permissions such as packages: write for publishing; GitHub explicitly recommends setting permissions for contents and packages when using workflows with packages. [\[22\]](https://docs.github.com/en/packages/learn-github-packages/about-permissions-for-github-packages?utm_source=chatgpt.com)

### Add a CI workflow

Create .github/workflows/ci.yml:

name: ci

on:  
  pull\_request:  
  push:  
    branches: \["main"\]

permissions:  
  contents: read  
  packages: write

env:  
  REGISTRY: ghcr.io  
  IMAGE\_API: ${{ github.repository }}-api  
  IMAGE\_WEB: ${{ github.repository }}-web

jobs:  
  test-and-build:  
    runs-on: ubuntu-latest

    steps:  
      \- name: Checkout  
        uses: actions/checkout@v4

      \- name: Set up Docker Buildx  
        uses: docker/setup-buildx-action@v3

      \# Log in only when pushing to main (PRs should not publish images).  
      \- name: Log in to GHCR  
        if: github.event\_name \== 'push'  
        uses: docker/login-action@v3  
        with:  
          registry: ${{ env.REGISTRY }}  
          username: ${{ github.actor }}  
          password: ${{ secrets.GITHUB\_TOKEN }}

      \# Basic API “unit test”: build the api image, run it, curl it.  
      \- name: Build API image (local)  
        uses: docker/build-push-action@v6  
        with:  
          context: .  
          file: api/Dockerfile  
          load: true  
          tags: local/api:test  
          cache-from: type=gha  
          cache-to: type=gha,mode=max

      \- name: Smoke test API container  
        run: |  
          docker run \-d \--rm \-p 18000:8000 \--name api\_smoke \-e DB\_PATH=/tmp/test.db local/api:test  
          python \-c "import time; time.sleep(2)"  
          curl \-fsS http://localhost:18000/api/healthz  
          docker logs api\_smoke  
          docker stop api\_smoke

      \# On main, also push both images to GHCR using commit SHA tags.  
      \- name: Build and push API (GHCR)  
        if: github.event\_name \== 'push'  
        uses: docker/build-push-action@v6  
        with:  
          context: .  
          file: api/Dockerfile  
          push: true  
          tags: |  
            ${{ env.REGISTRY }}/${{ env.IMAGE\_API }}:sha-${{ github.sha }}  
          cache-from: type=gha  
          cache-to: type=gha,mode=max

      \- name: Build and push Web (GHCR)  
        if: github.event\_name \== 'push'  
        uses: docker/build-push-action@v6  
        with:  
          context: .  
          file: web/Dockerfile  
          push: true  
          tags: |  
            ${{ env.REGISTRY }}/${{ env.IMAGE\_WEB }}:sha-${{ github.sha }}  
          cache-from: type=gha  
          cache-to: type=gha,mode=max

What’s happening:

A workflow is defined in YAML and is composed of jobs/steps, as GitHub documents. [\[18\]](https://docs.github.com/actions/using-workflows/workflow-syntax-for-github-actions?utm_source=chatgpt.com)  
docker/setup-buildx-action creates a Buildx builder, and docker/build-push-action builds/pushes using Buildx/BuildKit (including cache). [\[32\]](https://github.com/docker/setup-buildx-action?utm_source=chatgpt.com)  
We use GH Actions cache exporter/importer features via cache-from/cache-to. This is part of the BuildKit-centric CI story Docker documents. [\[33\]](https://docs.docker.com/build/ci/github-actions/cache/?utm_source=chatgpt.com)  
We authenticate to registries using docker/login-action. [\[34\]](https://github.com/docker/login-action?utm_source=chatgpt.com)

Example “success” output you’ll see in Actions (high-level):

Login Succeeded  
\#...  
pushing ghcr.io/OWNER/REPO-api:sha-\<commit\>  
pushing ghcr.io/OWNER/REPO-web:sha-\<commit\>

Common pitfalls:

If you forget permissions: packages: write, you’ll often see 403-like failures when pushing to GHCR; GitHub’s docs specifically tell you to set workflow token permissions for package publishing scenarios. [\[35\]](https://docs.github.com/en/packages/managing-github-packages-using-github-actions-workflows/publishing-and-installing-a-package-with-github-actions?utm_source=chatgpt.com)  
If your workflow runs from a forked PR, GITHUB\_TOKEN permissions are typically restricted (read-only); GitHub notes fork behavior for GITHUB\_TOKEN in package contexts. [\[36\]](https://docs.github.com/en/packages/managing-github-packages-using-github-actions-workflows/publishing-and-installing-a-package-with-github-actions?utm_source=chatgpt.com)  
In org settings, you may need to explicitly grant the repository access to the package (Actions access) depending on how the package is scoped; GitHub documents package permissions and access control. [\[37\]](https://docs.github.com/en/packages/learn-github-packages/about-permissions-for-github-packages?utm_source=chatgpt.com)

Commit and push:

git add .github/workflows/ci.yml  
git commit \-m "Add CI: build/test and push images to GHCR"  
git push

## Deploying to Azure and production hardening

This tutorial targets **Azure Container Apps** for production deployment because it’s designed for running containers with managed orchestration and supports secrets, environment variables, ingress controls, and calling between apps in the same environment. [\[38\]](https://learn.microsoft.com/en-us/azure/container-apps/environment?utm_source=chatgpt.com)

### Production architecture on Azure

For production, we keep two containers but deploy them as **two Container Apps** in the same Container Apps environment:

* modern-docker-stack-api (internal ingress enabled, not public)

* modern-docker-stack-web (public ingress enabled)

Why: your browser cannot reach an internal-only API, so the web container must proxy /api/\* to the API container app from inside the environment—exactly what our Nginx reverse proxy does.

Container Apps networking: you can enable ingress as public or limited to the environment, and Container Apps can communicate within the same environment using documented methods. [\[39\]](https://learn.microsoft.com/en-us/azure/container-apps/connect-apps?utm_source=chatgpt.com)

### Registry choice for Azure: GHCR vs ACR

**Option A (simplest for a tutorial): deploy from GHCR**  
Azure Container Apps supports images from GHCR, but Microsoft explicitly notes that when using non-ACR registries like GHCR, you must configure the container app to authenticate to the registry even if the image is public. [\[40\]](https://learn.microsoft.com/en-us/azure/container-apps/github-actions?utm_source=chatgpt.com)

This means you will almost always end up creating and storing a credential (often a GitHub PAT with read:packages) as an Azure secret.

**Option B (recommended for “real” production): deploy from ACR**  
Microsoft’s Container Apps docs highlight managed identity integration with Azure Container Registry, which avoids username/password registry auth at runtime. [\[41\]](https://learn.microsoft.com/en-us/azure/container-apps/containers?utm_source=chatgpt.com)  
A common production practice is: CI pushes to ACR (or copies from GHCR to ACR) and the runtime pulls from ACR with managed identity.

This tutorial continues with GHCR to satisfy the “use GHCR” requirement, then calls out the ACR hardening path.

### State and SQLite in production (important caveats)

SQLite is a file-based database. In container orchestration, that implies storage and scaling constraints:

* Without a persistent volume, app restarts can lose data (containers are meant to be ephemeral). [\[25\]](https://docs.docker.com/build/building/best-practices/)

* With multiple replicas, you risk divergent SQLite files unless all replicas share a safe storage mechanism (which introduces lock semantics and network filesystem behavior).

Azure Container Apps supports storage mounts including ephemeral replica-scoped storage and Azure Files. Microsoft documents replica-scoped ephemeral storage (similar to Kubernetes EmptyDir) and separately documents mounting Azure Files shares. [\[42\]](https://learn.microsoft.com/en-us/azure/container-apps/storage-mounts?utm_source=chatgpt.com)

**Critical pitfall: SQLite \+ SMB mounts**  
Microsoft’s recommended Azure Files SMB mount options include nobrl (disable byte-range lock requests) for applications that have challenges with POSIX locks. [\[43\]](https://learn.microsoft.com/en-us/troubleshoot/azure/azure-kubernetes/storage/mountoptions-settings-azure-files)  
If your platform does not let you set needed mount options, SQLite can hit “database is locked” behaviors on certain network filesystems. This is a strong reason to use SQLite only for low-scale/single-instance production, or to move to a client-server DB (Postgres/MySQL) for scalable production.

### Deploying with GitHub Actions using Azure OIDC (best practice)

Long-lived Azure credentials in GitHub Secrets are increasingly discouraged. GitHub and Microsoft document using OpenID Connect (OIDC) so workflows can authenticate to Azure without storing long-lived secrets. [\[44\]](https://docs.github.com/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-azure?utm_source=chatgpt.com)

High-level steps:

1. Create an Azure identity (service principal / app registration) and add a federated credential that trusts your GitHub repo. [\[45\]](https://docs.github.com/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-azure?utm_source=chatgpt.com)

2. Store non-secret identifiers in GitHub Secrets/Variables (tenant ID, subscription ID, client ID). [\[46\]](https://learn.microsoft.com/en-us/azure/developer/github/connect-from-azure-openid-connect?utm_source=chatgpt.com)

3. Use azure/login in GitHub Actions with id-token: write permission to obtain a short-lived token. [\[47\]](https://github.com/Azure/login?utm_source=chatgpt.com)

### Azure deployment workflow example

Create .github/workflows/deploy-azure.yml:

name: deploy-azure

on:  
  push:  
    branches: \["main"\]

permissions:  
  contents: read  
  id-token: write

env:  
  RG: rg-modern-docker-stack  
  LOCATION: westeurope  
  ENV\_NAME: env-modern-docker-stack  
  API\_APP: modern-docker-stack-api  
  WEB\_APP: modern-docker-stack-web  
  REGISTRY: ghcr.io  
  IMAGE\_API: ${{ github.repository }}-api  
  IMAGE\_WEB: ${{ github.repository }}-web  
  TAG: sha-${{ github.sha }}

jobs:  
  deploy:  
    runs-on: ubuntu-latest  
    steps:  
      \- name: Azure login (OIDC)  
        uses: azure/login@v2  
        with:  
          client-id: ${{ secrets.AZURE\_CLIENT\_ID }}  
          tenant-id: ${{ secrets.AZURE\_TENANT\_ID }}  
          subscription-id: ${{ secrets.AZURE\_SUBSCRIPTION\_ID }}

      \- name: Install Azure Container Apps extension  
        run: |  
          az extension add \--name containerapp \--upgrade

      \- name: Create resource group (idempotent)  
        run: |  
          az group create \-n "${RG}" \-l "${LOCATION}"

      \- name: Create Container Apps environment (idempotent)  
        run: |  
          az containerapp env create \\  
            \-n "${ENV\_NAME}" \\  
            \-g "${RG}" \\  
            \-l "${LOCATION}"

      \# IMPORTANT:  
      \# When deploying from GHCR, you must configure registry auth even if the image is public.  
      \# Store GHCR\_USERNAME / GHCR\_TOKEN as GitHub secrets.  
      \- name: Deploy API (internal ingress)  
        run: |  
          az containerapp create \\  
            \-n "${API\_APP}" \\  
            \-g "${RG}" \\  
            \--environment "${ENV\_NAME}" \\  
            \--image "${REGISTRY}/${IMAGE\_API}:${TAG}" \\  
            \--registry-server "${REGISTRY}" \\  
            \--registry-username "${{ secrets.GHCR\_USERNAME }}" \\  
            \--registry-password "${{ secrets.GHCR\_TOKEN }}" \\  
            \--ingress internal \\  
            \--target-port 8000 \\  
            \--env-vars DB\_PATH=/data/app.db

      \- name: Deploy Web (public ingress)  
        run: |  
          \# API internal FQDN will exist because ingress is enabled (internal).  
          \# For simplicity we set API\_UPSTREAM to the API app URL.  
          API\_HOST="http://${API\_APP}"  
          az containerapp create \\  
            \-n "${WEB\_APP}" \\  
            \-g "${RG}" \\  
            \--environment "${ENV\_NAME}" \\  
            \--image "${REGISTRY}/${IMAGE\_WEB}:${TAG}" \\  
            \--registry-server "${REGISTRY}" \\  
            \--registry-username "${{ secrets.GHCR\_USERNAME }}" \\  
            \--registry-password "${{ secrets.GHCR\_TOKEN }}" \\  
            \--ingress external \\  
            \--target-port 80 \\  
            \--env-vars API\_UPSTREAM="${API\_HOST}:8000"

      \- name: Show web URL  
        run: |  
          az containerapp show \-n "${WEB\_APP}" \-g "${RG}" \--query properties.configuration.ingress.fqdn \-o tsv

What’s happening and why it matches best practices:

OIDC avoids storing long-lived Azure credentials; GitHub’s Azure OIDC documentation describes this trust relationship and the use of azure/login. [\[48\]](https://docs.github.com/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-azure?utm_source=chatgpt.com)  
When deploying from GHCR, Container Apps requires registry authentication configuration even for public images—Microsoft explicitly calls this out. [\[40\]](https://learn.microsoft.com/en-us/azure/container-apps/github-actions?utm_source=chatgpt.com)  
Container Apps environments are the boundary that groups apps and are managed by the platform (OS upgrades, scaling, failover). [\[49\]](https://learn.microsoft.com/en-us/azure/container-apps/environment?utm_source=chatgpt.com)

Deployment pitfalls:

If you try to deploy from GHCR without setting registry credentials, the app will fail to pull. Microsoft’s GH Actions guidance for Container Apps explicitly warns about this for GHCR-like registries. [\[40\]](https://learn.microsoft.com/en-us/azure/container-apps/github-actions?utm_source=chatgpt.com)  
If you intend the API to be internal-only but your browser calls it directly (client-side), it won’t work. This is why we proxy /api/\* through the web container. Container Apps ingress can be restricted to intra-environment traffic. [\[50\]](https://learn.microsoft.com/en-us/azure/container-apps/networking?utm_source=chatgpt.com)  
If you scale the API to multiple replicas while using SQLite on local filesystem or replica-scoped storage, you’ll get inconsistent databases per replica. Container Apps storage docs note replica-scoped storage is scoped to a single replica (similar to EmptyDir). [\[51\]](https://learn.microsoft.com/en-us/azure/container-apps/storage-mounts?utm_source=chatgpt.com)

### Making SQLite less risky on Azure

If you insist on SQLite in production, treat it as **single-instance** and be deliberate about storage:

* Use a storage mount (Azure Files) for /data so restarts don’t wipe the database. [\[52\]](https://learn.microsoft.com/en-us/azure/container-apps/storage-mounts-azure-files?utm_source=chatgpt.com)

* Be aware SMB file-locking semantics can break SQLite unless mount options are chosen carefully; Microsoft’s recommended options include nobrl for lock challenges. [\[43\]](https://learn.microsoft.com/en-us/troubleshoot/azure/azure-kubernetes/storage/mountoptions-settings-azure-files)

* Consider instead: keep SQLite for dev, migrate production to Postgres (managed) while preserving the same container build/test workflows.

If you decide to use Azure Files with Container Apps, start from Microsoft’s “Use storage mounts” and “Azure Files volume mount” tutorials. [\[53\]](https://learn.microsoft.com/en-us/azure/container-apps/storage-mounts?utm_source=chatgpt.com)

### Production hardening checklist (container-centric)

This checklist is grounded in Docker’s own build best practices and Container Apps operational primitives:

Prefer multi-stage builds for smaller runtime images. [\[54\]](https://docs.docker.com/build/building/best-practices/)  
Use .dockerignore to shrink build context and speed builds. [\[25\]](https://docs.docker.com/build/building/best-practices/)  
Run as a non-root user where possible. [\[28\]](https://docs.docker.com/build/building/best-practices/)  
Pin base image versions thoughtfully; Docker discusses the tradeoff between tag mutability and digest pinning. [\[15\]](https://docs.docker.com/build/building/best-practices/)  
Use BuildKit cache mounts and CI caching to keep builds fast. [\[55\]](https://docs.docker.com/build/cache/optimize/?utm_source=chatgpt.com)  
Use secrets for credentials and inject them as environment variables rather than baking them into images; Container Apps supports secrets and secret-referenced env vars. [\[56\]](https://learn.microsoft.com/en-us/azure/container-apps/manage-secrets?utm_source=chatgpt.com)

## Choosing technologies and further reading

### Choosing the web \+ backend stack

A simple containerized app usually has three layers of decisions:

**Backend framework**  
Pick something your team can maintain. FastAPI, Express, and .NET minimal APIs are all viable; the “container story” is similar as long as you can run a single process listening on a port and have health endpoints.

**Web UI strategy**  
For a tutorial, static HTML \+ JS behind Nginx is “smallest moving parts.” For real apps, React/Vue/Svelte build steps fit naturally into multi-stage builds (build in Node stage, serve in Nginx stage). Multi-stage builds are explicitly recommended for keeping runtime images small. [\[15\]](https://docs.docker.com/build/building/best-practices/)

**Database choice**  
SQLite is perfect for: \- Single-instance apps \- Embedded/edge deployments \- Developer laptops \- Low-write workloads

SQLite becomes risky when: \- You scale out to multiple replicas (multiple independent files) \- You rely on network filesystem semantics \- You need HA/point-in-time restore

On Azure specifically, storage mounts are possible, but SMB lock behavior can be problematic (see Microsoft’s mount options guidance including nobrl). [\[57\]](https://learn.microsoft.com/en-us/troubleshoot/azure/azure-kubernetes/storage/mountoptions-settings-azure-files)  
A common upgrade path is moving production to a managed DB (Postgres) while keeping the same CI pipeline that builds your API container.

### Choosing Compose vs “real orchestration”

Compose is intentionally optimized for dev/test and small deployments, and Docker documents it as a way to define services in YAML and run them with one command across environmentsincluding CI. [\[58\]](https://docs.docker.com/compose/?utm_source=chatgpt.com)  
When you move to production cloud, you typically choose a managed orchestrator:

* Azure Container Apps: managed orchestration, supports ingress controls, secrets/env vars, communication within an environment. [\[59\]](https://learn.microsoft.com/en-us/azure/container-apps/environment?utm_source=chatgpt.com)

* AKS: maximum control, but maximum ops burden; you’ll manage Kubernetes more directly (not covered here).

### Choosing container registries

**GHCR** is ideal when you’re already using GitHub and want repo-associated images and GitHub-native permissions. [\[60\]](https://docs.github.com/packages/working-with-a-github-packages-registry/working-with-the-container-registry?utm_source=chatgpt.com)  
**ACR** is ideal for production on Azure when you want managed identity-based pulls (no registry password at runtime). [\[41\]](https://learn.microsoft.com/en-us/azure/container-apps/containers?utm_source=chatgpt.com)  
Docker Hub may work for simple cases, but rate limits and private repo limitations often push teams toward GHCR/ACR; Container Apps docs even mention Docker Hub download limits as an operational risk. [\[41\]](https://learn.microsoft.com/en-us/azure/container-apps/containers?utm_source=chatgpt.com)

### Further reading links

Docker Build overview (BuildKit \+ Buildx relationship). [\[11\]](https://docs.docker.com/build/concepts/overview/?utm_source=chatgpt.com)  
BuildKit documentation (default builder, capabilities). [\[30\]](https://docs.docker.com/build/buildkit/?utm_source=chatgpt.com)  
docker buildx build reference. [\[29\]](https://docs.docker.com/reference/cli/docker/buildx/build/?utm_source=chatgpt.com)  
Docker multi-stage builds. [\[14\]](https://docs.docker.com/build/building/multi-stage/?utm_source=chatgpt.com)  
Docker build best practices (.dockerignore, non-root, pinning, CI builds). [\[61\]](https://docs.docker.com/build/building/best-practices/)  
Docker Compose fundamentals and CLI behavior. [\[62\]](https://docs.docker.com/compose/intro/compose-application-model/)  
Compose startup order using healthchecks. [\[23\]](https://docs.docker.com/compose/how-tos/startup-order/?utm_source=chatgpt.com)  
Compose profiles (optional services). [\[63\]](https://docs.docker.com/compose/how-tos/profiles/?utm_source=chatgpt.com)  
GitHub Container Registry (GHCR) docs and permissions model. [\[21\]](https://docs.github.com/packages/working-with-a-github-packages-registry/working-with-the-container-registry?utm_source=chatgpt.com)  
GitHub Actions workflow syntax \+ publishing Docker images guidance. [\[64\]](https://docs.github.com/actions/using-workflows/workflow-syntax-for-github-actions?utm_source=chatgpt.com)  
Docker Buildx build/push GitHub Action (build-push-action). [\[20\]](https://github.com/docker/build-push-action?utm_source=chatgpt.com)  
GitHub Codespaces dev containers overview (devcontainer.json). [\[5\]](https://docs.github.com/codespaces/setting-up-your-project-for-codespaces/introduction-to-dev-containers)  
Deploy to Azure Container Apps with GitHub Actions (including GHCR auth requirement). [\[40\]](https://learn.microsoft.com/en-us/azure/container-apps/github-actions?utm_source=chatgpt.com)  
GitHub OIDC with Azure \+ Azure login action (secretless auth). [\[44\]](https://docs.github.com/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-azure?utm_source=chatgpt.com)  
Azure Container Apps secrets and environment variables. [\[56\]](https://learn.microsoft.com/en-us/azure/container-apps/manage-secrets?utm_source=chatgpt.com)  
Azure Container Apps storage mounts \+ Azure Files mounting tutorial. [\[53\]](https://learn.microsoft.com/en-us/azure/container-apps/storage-mounts?utm_source=chatgpt.com)  
Recommended Azure Files mount options including nobrl for lock challenges. [\[43\]](https://learn.microsoft.com/en-us/troubleshoot/azure/azure-kubernetes/storage/mountoptions-settings-azure-files)

---

[\[1\]](https://docs.docker.com/compose/?utm_source=chatgpt.com) [\[58\]](https://docs.docker.com/compose/?utm_source=chatgpt.com) Docker Compose

[https://docs.docker.com/compose/?utm\_source=chatgpt.com](https://docs.docker.com/compose/?utm_source=chatgpt.com)

[\[2\]](https://docs.docker.com/build/buildkit/?utm_source=chatgpt.com) [\[7\]](https://docs.docker.com/build/buildkit/?utm_source=chatgpt.com) [\[10\]](https://docs.docker.com/build/buildkit/?utm_source=chatgpt.com) [\[13\]](https://docs.docker.com/build/buildkit/?utm_source=chatgpt.com) [\[30\]](https://docs.docker.com/build/buildkit/?utm_source=chatgpt.com) BuildKit | Docker Docs

[https://docs.docker.com/build/buildkit/?utm\_source=chatgpt.com](https://docs.docker.com/build/buildkit/?utm_source=chatgpt.com)

[\[3\]](https://docs.docker.com/build/building/multi-stage/?utm_source=chatgpt.com) [\[14\]](https://docs.docker.com/build/building/multi-stage/?utm_source=chatgpt.com) Multi-stage builds

[https://docs.docker.com/build/building/multi-stage/?utm\_source=chatgpt.com](https://docs.docker.com/build/building/multi-stage/?utm_source=chatgpt.com)

[\[4\]](https://docs.github.com/actions/guides/publishing-docker-images?utm_source=chatgpt.com) [\[19\]](https://docs.github.com/actions/guides/publishing-docker-images?utm_source=chatgpt.com) Publishing Docker images

[https://docs.github.com/actions/guides/publishing-docker-images?utm\_source=chatgpt.com](https://docs.github.com/actions/guides/publishing-docker-images?utm_source=chatgpt.com)

[\[5\]](https://docs.github.com/codespaces/setting-up-your-project-for-codespaces/introduction-to-dev-containers) Introduction to dev containers \- GitHub Docs

[https://docs.github.com/codespaces/setting-up-your-project-for-codespaces/introduction-to-dev-containers](https://docs.github.com/codespaces/setting-up-your-project-for-codespaces/introduction-to-dev-containers)

[\[6\]](https://docs.docker.com/compose/intro/compose-application-model/) [\[62\]](https://docs.docker.com/compose/intro/compose-application-model/) How Compose works | Docker Docs

[https://docs.docker.com/compose/intro/compose-application-model/](https://docs.docker.com/compose/intro/compose-application-model/)

[\[8\]](https://docs.github.com/actions/using-workflows/workflow-syntax-for-github-actions?utm_source=chatgpt.com) [\[18\]](https://docs.github.com/actions/using-workflows/workflow-syntax-for-github-actions?utm_source=chatgpt.com) [\[64\]](https://docs.github.com/actions/using-workflows/workflow-syntax-for-github-actions?utm_source=chatgpt.com) Workflow syntax for GitHub Actions

[https://docs.github.com/actions/using-workflows/workflow-syntax-for-github-actions?utm\_source=chatgpt.com](https://docs.github.com/actions/using-workflows/workflow-syntax-for-github-actions?utm_source=chatgpt.com)

[\[9\]](https://learn.microsoft.com/en-us/azure/container-apps/environment?utm_source=chatgpt.com) [\[38\]](https://learn.microsoft.com/en-us/azure/container-apps/environment?utm_source=chatgpt.com) [\[49\]](https://learn.microsoft.com/en-us/azure/container-apps/environment?utm_source=chatgpt.com) [\[59\]](https://learn.microsoft.com/en-us/azure/container-apps/environment?utm_source=chatgpt.com) Azure Container Apps environments

[https://learn.microsoft.com/en-us/azure/container-apps/environment?utm\_source=chatgpt.com](https://learn.microsoft.com/en-us/azure/container-apps/environment?utm_source=chatgpt.com)

[\[11\]](https://docs.docker.com/build/concepts/overview/?utm_source=chatgpt.com) Docker Build Overview

[https://docs.docker.com/build/concepts/overview/?utm\_source=chatgpt.com](https://docs.docker.com/build/concepts/overview/?utm_source=chatgpt.com)

[\[12\]](https://docs.docker.com/reference/cli/docker/buildx/build/?utm_source=chatgpt.com) [\[29\]](https://docs.docker.com/reference/cli/docker/buildx/build/?utm_source=chatgpt.com) docker buildx build

[https://docs.docker.com/reference/cli/docker/buildx/build/?utm\_source=chatgpt.com](https://docs.docker.com/reference/cli/docker/buildx/build/?utm_source=chatgpt.com)

[\[15\]](https://docs.docker.com/build/building/best-practices/) [\[24\]](https://docs.docker.com/build/building/best-practices/) [\[25\]](https://docs.docker.com/build/building/best-practices/) [\[28\]](https://docs.docker.com/build/building/best-practices/) [\[54\]](https://docs.docker.com/build/building/best-practices/) [\[61\]](https://docs.docker.com/build/building/best-practices/) Best practices | Docker Docs

[https://docs.docker.com/build/building/best-practices/](https://docs.docker.com/build/building/best-practices/)

[\[16\]](https://docs.docker.com/compose/how-tos/startup-order/?utm_source=chatgpt.com) [\[23\]](https://docs.docker.com/compose/how-tos/startup-order/?utm_source=chatgpt.com) Control startup order \- Docker Compose

[https://docs.docker.com/compose/how-tos/startup-order/?utm\_source=chatgpt.com](https://docs.docker.com/compose/how-tos/startup-order/?utm_source=chatgpt.com)

[\[17\]](https://docs.docker.com/reference/cli/docker/compose/) docker compose | Docker Docs

[https://docs.docker.com/reference/cli/docker/compose/](https://docs.docker.com/reference/cli/docker/compose/)

[\[20\]](https://github.com/docker/build-push-action?utm_source=chatgpt.com) GitHub Action to build and push Docker images with Buildx

[https://github.com/docker/build-push-action?utm\_source=chatgpt.com](https://github.com/docker/build-push-action?utm_source=chatgpt.com)

[\[21\]](https://docs.github.com/packages/working-with-a-github-packages-registry/working-with-the-container-registry?utm_source=chatgpt.com) [\[31\]](https://docs.github.com/packages/working-with-a-github-packages-registry/working-with-the-container-registry?utm_source=chatgpt.com) [\[60\]](https://docs.github.com/packages/working-with-a-github-packages-registry/working-with-the-container-registry?utm_source=chatgpt.com) Working with the Container registry

[https://docs.github.com/packages/working-with-a-github-packages-registry/working-with-the-container-registry?utm\_source=chatgpt.com](https://docs.github.com/packages/working-with-a-github-packages-registry/working-with-the-container-registry?utm_source=chatgpt.com)

[\[22\]](https://docs.github.com/en/packages/learn-github-packages/about-permissions-for-github-packages?utm_source=chatgpt.com) [\[37\]](https://docs.github.com/en/packages/learn-github-packages/about-permissions-for-github-packages?utm_source=chatgpt.com) About permissions for GitHub Packages

[https://docs.github.com/en/packages/learn-github-packages/about-permissions-for-github-packages?utm\_source=chatgpt.com](https://docs.github.com/en/packages/learn-github-packages/about-permissions-for-github-packages?utm_source=chatgpt.com)

[\[26\]](https://docs.docker.com/build/buildkit/frontend/?utm_source=chatgpt.com) Custom Dockerfile syntax

[https://docs.docker.com/build/buildkit/frontend/?utm\_source=chatgpt.com](https://docs.docker.com/build/buildkit/frontend/?utm_source=chatgpt.com)

[\[27\]](https://docs.docker.com/build/cache/optimize/?utm_source=chatgpt.com) [\[55\]](https://docs.docker.com/build/cache/optimize/?utm_source=chatgpt.com) Optimize cache usage in builds

[https://docs.docker.com/build/cache/optimize/?utm\_source=chatgpt.com](https://docs.docker.com/build/cache/optimize/?utm_source=chatgpt.com)

[\[32\]](https://github.com/docker/setup-buildx-action?utm_source=chatgpt.com) docker/setup-buildx-action

[https://github.com/docker/setup-buildx-action?utm\_source=chatgpt.com](https://github.com/docker/setup-buildx-action?utm_source=chatgpt.com)

[\[33\]](https://docs.docker.com/build/ci/github-actions/cache/?utm_source=chatgpt.com) Cache management with GitHub Actions

[https://docs.docker.com/build/ci/github-actions/cache/?utm\_source=chatgpt.com](https://docs.docker.com/build/ci/github-actions/cache/?utm_source=chatgpt.com)

[\[34\]](https://github.com/docker/login-action?utm_source=chatgpt.com) GitHub Action to login against a Docker registry

[https://github.com/docker/login-action?utm\_source=chatgpt.com](https://github.com/docker/login-action?utm_source=chatgpt.com)

[\[35\]](https://docs.github.com/en/packages/managing-github-packages-using-github-actions-workflows/publishing-and-installing-a-package-with-github-actions?utm_source=chatgpt.com) [\[36\]](https://docs.github.com/en/packages/managing-github-packages-using-github-actions-workflows/publishing-and-installing-a-package-with-github-actions?utm_source=chatgpt.com) Publishing and installing a package with GitHub Actions

[https://docs.github.com/en/packages/managing-github-packages-using-github-actions-workflows/publishing-and-installing-a-package-with-github-actions?utm\_source=chatgpt.com](https://docs.github.com/en/packages/managing-github-packages-using-github-actions-workflows/publishing-and-installing-a-package-with-github-actions?utm_source=chatgpt.com)

[\[39\]](https://learn.microsoft.com/en-us/azure/container-apps/connect-apps?utm_source=chatgpt.com) Communicate between container apps in Azure ...

[https://learn.microsoft.com/en-us/azure/container-apps/connect-apps?utm\_source=chatgpt.com](https://learn.microsoft.com/en-us/azure/container-apps/connect-apps?utm_source=chatgpt.com)

[\[40\]](https://learn.microsoft.com/en-us/azure/container-apps/github-actions?utm_source=chatgpt.com) Deploy to Azure Container Apps with GitHub Actions

[https://learn.microsoft.com/en-us/azure/container-apps/github-actions?utm\_source=chatgpt.com](https://learn.microsoft.com/en-us/azure/container-apps/github-actions?utm_source=chatgpt.com)

[\[41\]](https://learn.microsoft.com/en-us/azure/container-apps/containers?utm_source=chatgpt.com) Containers in Azure Container Apps \- Microsoft Learn

[https://learn.microsoft.com/en-us/azure/container-apps/containers?utm\_source=chatgpt.com](https://learn.microsoft.com/en-us/azure/container-apps/containers?utm_source=chatgpt.com)

[\[42\]](https://learn.microsoft.com/en-us/azure/container-apps/storage-mounts?utm_source=chatgpt.com) [\[51\]](https://learn.microsoft.com/en-us/azure/container-apps/storage-mounts?utm_source=chatgpt.com) [\[53\]](https://learn.microsoft.com/en-us/azure/container-apps/storage-mounts?utm_source=chatgpt.com) Use storage mounts in Azure Container Apps

[https://learn.microsoft.com/en-us/azure/container-apps/storage-mounts?utm\_source=chatgpt.com](https://learn.microsoft.com/en-us/azure/container-apps/storage-mounts?utm_source=chatgpt.com)

[\[43\]](https://learn.microsoft.com/en-us/troubleshoot/azure/azure-kubernetes/storage/mountoptions-settings-azure-files) [\[57\]](https://learn.microsoft.com/en-us/troubleshoot/azure/azure-kubernetes/storage/mountoptions-settings-azure-files) Recommended and useful mountOptions settings on Azure Files \- Azure | Microsoft Learn

[https://learn.microsoft.com/en-us/troubleshoot/azure/azure-kubernetes/storage/mountoptions-settings-azure-files](https://learn.microsoft.com/en-us/troubleshoot/azure/azure-kubernetes/storage/mountoptions-settings-azure-files)

[\[44\]](https://docs.github.com/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-azure?utm_source=chatgpt.com) [\[45\]](https://docs.github.com/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-azure?utm_source=chatgpt.com) [\[48\]](https://docs.github.com/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-azure?utm_source=chatgpt.com) Configuring OpenID Connect in Azure

[https://docs.github.com/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-azure?utm\_source=chatgpt.com](https://docs.github.com/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-azure?utm_source=chatgpt.com)

[\[46\]](https://learn.microsoft.com/en-us/azure/developer/github/connect-from-azure-openid-connect?utm_source=chatgpt.com) Use the Azure Login action with OpenID Connect

[https://learn.microsoft.com/en-us/azure/developer/github/connect-from-azure-openid-connect?utm\_source=chatgpt.com](https://learn.microsoft.com/en-us/azure/developer/github/connect-from-azure-openid-connect?utm_source=chatgpt.com)

[\[47\]](https://github.com/Azure/login?utm_source=chatgpt.com) Azure/login: Connect to Azure

[https://github.com/Azure/login?utm\_source=chatgpt.com](https://github.com/Azure/login?utm_source=chatgpt.com)

[\[50\]](https://learn.microsoft.com/en-us/azure/container-apps/networking?utm_source=chatgpt.com) Networking in Azure Container Apps environment

[https://learn.microsoft.com/en-us/azure/container-apps/networking?utm\_source=chatgpt.com](https://learn.microsoft.com/en-us/azure/container-apps/networking?utm_source=chatgpt.com)

[\[52\]](https://learn.microsoft.com/en-us/azure/container-apps/storage-mounts-azure-files?utm_source=chatgpt.com) Create an Azure Files volume mount in Azure Container ...

[https://learn.microsoft.com/en-us/azure/container-apps/storage-mounts-azure-files?utm\_source=chatgpt.com](https://learn.microsoft.com/en-us/azure/container-apps/storage-mounts-azure-files?utm_source=chatgpt.com)

[\[56\]](https://learn.microsoft.com/en-us/azure/container-apps/manage-secrets?utm_source=chatgpt.com) Manage secrets in Azure Container Apps

[https://learn.microsoft.com/en-us/azure/container-apps/manage-secrets?utm\_source=chatgpt.com](https://learn.microsoft.com/en-us/azure/container-apps/manage-secrets?utm_source=chatgpt.com)

[\[63\]](https://docs.docker.com/compose/how-tos/profiles/?utm_source=chatgpt.com) Use service profiles

[https://docs.docker.com/compose/how-tos/profiles/?utm\_source=chatgpt.com](https://docs.docker.com/compose/how-tos/profiles/?utm_source=chatgpt.com)
